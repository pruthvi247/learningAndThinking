![[Pasted image 20250618104925.png]]

1. Machine Learning: Core algorithms, statistics, and model training techniques.
    
2. Deep Learning: Hierarchical neural networks learning complex representations automatically.
    
3. Neural Networks: Layered architectures efficiently model nonlinear relationships accurately.
    
4. NLP: Techniques to process and understand natural language text.
    
5. Computer Vision: Algorithms interpreting and analyzing visual data effectively
    
6. Reinforcement Learning: Distributed traffic across multiple servers for reliability.
    
7. Generative Models: Creating new data samples using learned data.
    
8. LLM: Generates human-like text using massive pre-trained data.
    
9. Transformers: Self-attention-based architecture powering modern AI models.
    
10. Feature Engineering: Designing informative features to improve model performance significantly.
    
11. Supervised Learning: Learns useful representations without labeled data.
    
12. Bayesian Learning: Incorporate uncertainty using probabilistic model approaches.
    
13. Prompt Engineering: Crafting effective inputs to guide generative model outputs.
    
14. AI Agents: Autonomous systems that perceive, decide, and act.
    
15. Fine-Tuning Models: Customizes pre-trained models for domain-specific tasks.
    
16. Multimodal Models: Processes and generates across multiple data types like images, videos, and text.
    
17. Embeddings: Transforms input into machine-readable vector formats.
    
18. Vector Search: Finds similar items using dense vector embeddings.
    
19. Model Evaluation: Assessing predictive performance using validation techniques.
    
20. AI Infrastructure: Deploying scalable systems to support AI operations.
    
![[Pasted image 20250618104959.png]]

21. Large Language Models  
    These are the core engines behind Retrieval-Augmented Generation (RAG), responsible for understanding queries and generating coherent and contextual responses. Some common LLM options are OpenAI GPT models, Llama, Claude, Gemini, Mistral, DeepSeek, Qwen 2.5, Gemma, etc.
    
22. Frameworks and Model Access  
    These tools simplify the integration of LLMs into your applications by handling prompt orchestration, model switching, memory, chaining, and routing. Common tools are Langchain, LlamaIndex, Haystack, Ollama, Hugging Face, and OpenRouter.
    
23. Databases  
    RAG applications rely on storing and retrieving relevant information. These vector databases are optimized for similarity search, while relational options like Postgres offer structured storage. Tools are Postgres, FAISS, Milvus, pgVector, Weaviate, Pinecone, Chroma, etc.
    
24. Data Extraction  
    To populate your knowledge base, these tools help extract structured information from unstructured sources like PDFs, websites, and APIs. Some common tools are Llamaparse, Docking, Megaparser, Firecrawl, ScrapeGraph AI, Document AI, and Claude API.
    
25. Text Embeddings  
    Embeddings convert text into high-dimensional vectors that enable semantic similarity search, which is a critical step for connecting queries with relevant context in RAG. Common tools are Nomic, OpenAI, Cognita, Gemini, LLMWare, Cohere, JinaAI, and Ollama.

